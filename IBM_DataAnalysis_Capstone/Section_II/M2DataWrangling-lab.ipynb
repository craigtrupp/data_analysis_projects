{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45 to 60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will be performing data wrangling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Identify duplicate values in the dataset.\n",
    "\n",
    "*   Remove duplicate values from the dataset.\n",
    "\n",
    "*   Identify missing values in the dataset.\n",
    "\n",
    "*   Impute the missing values in the dataset.\n",
    "\n",
    "*   Normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will identify duplicate values in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many duplicate rows exist in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11552 11552\n",
      "154\n",
      "<class 'pandas.core.series.Series'>\n",
      "False    11398\n",
      "True       154\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(len(df), df.shape[0]) # All rows\n",
    "print(len(df[df.duplicated()])) # 154 here is a quick way to get all dupes\n",
    "dupes = df.duplicated()\n",
    "print(type(dupes))\n",
    "print(dupes.value_counts()) # series value counts on boolean series indicating if row is a dupe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "# How many duplicate values are there in the column Respondent? \n",
    "print(len(df[df['Respondent'].duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicate rows from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We would expect our length to be the shape of the original data frame (rows) : 11552 subtracted \n",
      "against the length above for found duplicates (154) : 11398 \n",
      "11398\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "df_no_dupes = df.drop_duplicates()\n",
    "print(\"\"\"We would expect our length to be the shape of the original data frame (rows) : {} subtracted \n",
    "against the length above for found duplicates (154) : {} \"\"\".format(df.shape[0], len(df) - len(df[df.duplicated()])))\n",
    "\n",
    "print(len(df_no_dupes)) # Nice they match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if duplicates were actually dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(len(df_no_dupes[df_no_dupes.duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respondent        0\n",
      "MainBranch        0\n",
      "Hobbyist          0\n",
      "OpenSourcer       0\n",
      "OpenSource       81\n",
      "               ... \n",
      "Sexuality       542\n",
      "Ethnicity       675\n",
      "Dependents      140\n",
      "SurveyLength     19\n",
      "SurveyEase       14\n",
      "Length: 85, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df_no_dupes.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many rows are missing in the column 'WorkLoc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df_no_dupes['WorkLoc'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bachelor’s degree (BA, BS, B.Eng., etc.)                                              5852\n",
      "Master’s degree (MA, MS, M.Eng., MBA, etc.)                                           2706\n",
      "Some college/university study without earning a degree                                1361\n",
      "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)     516\n",
      "Associate degree                                                                       383\n",
      "Other doctoral degree (Ph.D, Ed.D., etc.)                                              259\n",
      "Professional degree (JD, MD, etc.)                                                     154\n",
      "I never completed any formal education                                                  28\n",
      "Primary/elementary school                                                               27\n",
      "Name: EdLevel, dtype: int64\n",
      "\n",
      "\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "# After removing the duplicate rows, how many blank rows are there under the column EdLevel?\n",
    "print(df_no_dupes['EdLevel'].value_counts()) # would assume there after null values - here non null\n",
    "print('\\n')\n",
    "print(df_no_dupes['EdLevel'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# After removing the duplicate rows, how many rows are missing under the column Country?\n",
    "print(df_no_dupes['Country'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the  value counts for the column WorkLoc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Office                                            6806\n",
      "Home                                              3589\n",
      "Other place, such as a coworking space or cafe     971\n",
      "Name: WorkLoc, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df_no_dupes['WorkLoc'].value_counts())\n",
    "print(type(df_no_dupes['WorkLoc'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value that is most frequent (majority) in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6806 Office\n"
     ]
    }
   ],
   "source": [
    "#make a note of the majority value here, for future reference\n",
    "top_workloc_value, top_workloc_id  = df_no_dupes['WorkLoc'].value_counts(ascending=False)[0], df_no_dupes['WorkLoc'].value_counts(ascending=False).index[0]\n",
    "print(top_workloc_value, top_workloc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Office                                            6838\n",
      "Home                                              3589\n",
      "Other place, such as a coworking space or cafe     971\n",
      "Name: WorkLoc, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r8/mmfd5rgj7v51_80zhnq8v9zc0000gn/T/ipykernel_19752/2121531442.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_dupes['WorkLoc'].fillna(top_workloc_id, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "df_no_dupes['WorkLoc'].fillna(top_workloc_id, inplace=True)\n",
    "print(df_no_dupes['WorkLoc'].isna().sum()) # zero\n",
    "print(df_no_dupes['WorkLoc'].value_counts()) # 32 more for Office!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if imputing was successful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df_no_dupes['WorkLoc'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employed full-time    10968\n",
      "Employed part-time      430\n",
      "Name: Employment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  What is the majority category under the column Employment?\n",
    "print(df_no_dupes['Employment'].value_counts(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A health science (ex. nursing, pharmacy, radiology)                        24\n",
      "I never declared a major                                                  124\n",
      "Fine arts or performing arts (ex. graphic design, music, studio art)      161\n",
      "A humanities discipline (ex. literature, history, philosophy)             207\n",
      "A social science (ex. anthropology, psychology, political science)        210\n",
      "A business discipline (ex. accounting, finance, marketing)                244\n",
      "Mathematics or statistics                                                 372\n",
      "A natural science (ex. biology, chemistry, physics)                       403\n",
      "Web development or web design                                             410\n",
      "Another engineering discipline (ex. civil, electrical, mechanical)        759\n",
      "Information systems, information technology, or system administration     794\n",
      "Computer science, computer engineering, or software engineering          6953\n",
      "Name: UndergradMajor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Under the column \" UndergradMajor\", which category has the minimum number of rows?\n",
    "print(df_no_dupes['UndergradMajor'].value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.058200e+04\n",
       "mean     1.315967e+05\n",
       "std      2.947865e+05\n",
       "min      0.000000e+00\n",
       "25%      2.686800e+04\n",
       "50%      5.774500e+04\n",
       "75%      1.000000e+05\n",
       "max      2.000000e+06\n",
       "Name: ConvertedComp, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The column ‘ConvertedComp’ contains the annual compensation of the survey respondents. What is the best approach to impute the missing values in this column? \n",
    "display(df_no_dupes['ConvertedComp'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset that talk about compensation.\n",
    "\n",
    "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
    "\n",
    "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\".\n",
    "\n",
    "This makes it difficult to compare the total compensation of the developers.\n",
    "\n",
    "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
    "\n",
    "Once this column is ready, it makes comparison of salaries easy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the various categories in the column 'CompFreq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly     6073\n",
      "Monthly    4788\n",
      "Weekly      331\n",
      "Name: CompFreq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df_no_dupes['CompFreq'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click to see the **Hint**.\n",
    "\n",
    "<!--\n",
    "\n",
    "Use the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n",
    "\n",
    "If the CompFreq is Yearly then use the exising value in CompTotal\n",
    "If the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\n",
    "If the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "CompTotal    809\n",
      "CompFreq     206\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df_no_dupes['CompTotal'].dtypes) # no type transformation needed\n",
    "print(df_no_dupes[['CompTotal', 'CompFreq']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tupe in df_no_dupes.iloc[2:4, :].itertuples():\n",
    "#     print(tupe[1:5])\n",
    "    \n",
    "# for row in df_no_dupes.[2:4, ['']].iterrows():\n",
    "#     print(row['CompTotal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11398\n"
     ]
    }
   ],
   "source": [
    "annual_comp = []\n",
    "# for tupe in df_no_dupes[['CompFreq', 'CompTotal']].iloc[:2, :].itertuples():\n",
    "#     print(tupe) # Pandas(Index=0, CompFreq='Yearly', CompTotal=61000.0)\n",
    "    \n",
    "for tupe in df_no_dupes[['CompFreq', 'CompTotal']].itertuples():\n",
    "    # print(tupe) # Pandas(Index=0, CompFreq='Yearly', CompTotal=61000.0)\n",
    "    # print(tupe[1], tupe[2])\n",
    "    if pd.isnull(tupe[1]) or pd.isnull(tupe[2]): # if either the compfreq or comptotal is null, add zero to annual_comp\n",
    "        annual_comp.append(0.0)\n",
    "    elif tupe[1] == 'Yearly':\n",
    "        annual_comp.append(tupe[2]) # itertuples returns index in first[0] position, total is in the third index of the tupe iterator variable\n",
    "    elif tupe[1] == 'Monthly':\n",
    "        annual_comp.append(tupe[2] * 12)\n",
    "    elif tupe[1] == 'Weekly':\n",
    "        annual_comp.append(tupe[2] * 52)\n",
    "        \n",
    "print(len(annual_comp))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r8/mmfd5rgj7v51_80zhnq8v9zc0000gn/T/ipykernel_19752/100292337.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_dupes['NormalizedAnnualCompensation'] = annual_comp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CompFreq  CompTotal  NormalizedAnnualCompensation\n",
      "0    Yearly    61000.0                       61000.0\n",
      "1    Yearly   138000.0                      138000.0\n",
      "2    Yearly    90000.0                       90000.0\n",
      "3   Monthly    29000.0                      348000.0\n",
      "4    Yearly    90000.0                       90000.0\n",
      "5   Monthly     9500.0                      114000.0\n",
      "6   Monthly     3000.0                       36000.0\n",
      "7    Yearly   103000.0                      103000.0\n",
      "8    Yearly    69000.0                       69000.0\n",
      "9   Monthly     8000.0                       96000.0\n",
      "10  Monthly     7000.0                       84000.0\n",
      "11   Yearly   114000.0                      114000.0\n",
      "12   Weekly     2000.0                      104000.0\n",
      "13   Weekly    22000.0                     1144000.0\n",
      "14  Monthly    96000.0                     1152000.0\n",
      "15   Yearly   156000.0                      156000.0\n",
      "16   Yearly    18000.0                       18000.0\n",
      "17  Monthly     6400.0                       76800.0\n",
      "18  Monthly     5000.0                       60000.0\n",
      "19   Yearly   400000.0                      400000.0\n",
      "20   Yearly    47300.0                       47300.0\n",
      "21  Monthly    51500.0                      618000.0\n",
      "22   Yearly   345000.0                      345000.0\n",
      "23   Yearly    85000.0                       85000.0\n",
      "24   Yearly   107000.0                      107000.0\n",
      "25   Yearly    66000.0                       66000.0\n",
      "26   Yearly    76800.0                       76800.0\n",
      "27   Yearly    50000.0                       50000.0\n",
      "28   Yearly   800000.0                      800000.0\n",
      "29   Yearly    75000.0                       75000.0\n",
      "30  Monthly    18000.0                      216000.0\n",
      "31   Yearly   100000.0                      100000.0\n",
      "32   Yearly  1250000.0                     1250000.0\n",
      "33   Yearly    30000.0                       30000.0\n",
      "34   Yearly   550000.0                      550000.0\n",
      "35   Yearly        NaN                           0.0\n",
      "36  Monthly   700000.0                     8400000.0\n",
      "37  Monthly    40000.0                      480000.0\n",
      "38  Monthly     9000.0                      108000.0\n",
      "39  Monthly    11000.0                      132000.0\n",
      "40  Monthly   100000.0                     1200000.0\n",
      "41   Yearly    50000.0                       50000.0\n",
      "42   Yearly    33000.0                       33000.0\n",
      "43   Yearly   110000.0                      110000.0\n",
      "44   Yearly    66750.0                       66750.0\n",
      "45   Yearly   300000.0                      300000.0\n",
      "46   Weekly    67800.0                     3525600.0\n",
      "47   Yearly   155000.0                      155000.0\n",
      "48  Monthly    25000.0                      300000.0\n",
      "49   Yearly   100000.0                      100000.0\n"
     ]
    }
   ],
   "source": [
    "df_no_dupes['NormalizedAnnualCompensation'] = annual_comp\n",
    "print(df_no_dupes[['CompFreq', 'CompTotal', 'NormalizedAnnualCompensation']].iloc[:50, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# How many unique values are there in the CompFreq column?     \n",
    "\n",
    "print(df_no_dupes['CompFreq'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly     6073\n",
      "Monthly    4788\n",
      "Weekly      331\n",
      "Name: CompFreq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# After removing the duplicate rows, how many respondents are being paid yearly?\n",
    "print(df_no_dupes['CompFreq'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.139800e+04\n",
      "mean     5.697287e+06\n",
      "std      9.483867e+07\n",
      "min      0.000000e+00\n",
      "25%      4.350000e+04\n",
      "50%      9.000000e+04\n",
      "75%      3.000000e+05\n",
      "max      8.400000e+09\n",
      "Name: NormalizedAnnualCompensation, dtype: float64\n",
      "90000.0\n"
     ]
    }
   ],
   "source": [
    "# What is the median NormalizedAnnualCompensation?    \n",
    "\n",
    "print(df_no_dupes['NormalizedAnnualCompensation'].describe())\n",
    "print(df_no_dupes['NormalizedAnnualCompensation'].quantile(q=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
